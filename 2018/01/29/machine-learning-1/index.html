<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="励志成为一位大佬">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    机器学习之knn |
    
    春少 Blog</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>

<body>
<main class="content">
  <section class="outer">
  <article id="post-machine-learning-1" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="article-title" itemprop="name">
      机器学习之knn
    </h1>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/01/29/machine-learning-1/" class="article-date">
  <time datetime="2018-01-29T11:46:35.000Z" itemprop="datePublished">2018-01-29</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

                    </div>
                    

                        
                            




                                

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <p>机器学习很简单的入门——KNN近邻算法，这是一个用于将未知事物分类到已经事物分类中的算法。这个算法的原理其实很简单的，就是求两点之间的距离，通过距离大小的判断最为主要依据来判断得出未知事物与k个最相近的已知事物，在通过每个已知事物出现的标签次数，来决策出未知事物的最终分类结果。</p>
<p>再深入理解下knn，其实就是计算两事物的相似性程度，这其实是knn算法的本质——通过相似度来实现分类的功能；既然我们已经知道了knn算法的本质是计算相似性程度，那么我们就可以采用很多种方式来计算两者的相似程度了，比如我前文说的计算两个点之间的距离来计算相似度，就是计算欧式距离；我们还可以计算两个向量之间的余弦值来计算相似度，等等还有很多，具体的请点击链接 <a href="http://www.cnblogs.com/arachis/p/Similarity.html" target="_blank" rel="noopener">相似度计算</a> 。我最熟悉的就是一个欧拉距离，还有就是余弦相似度计算。</p>
<p>knn算法的具体步骤如下</p>
<ul>
<li>人工先进行分类，得出一个标准分类</li>
<li>对事物特征进行 one-hot编码，也就是向量化</li>
<li>对未知事物进行编码操作</li>
<li>计算未知事物与所有已知事物的空间距离</li>
<li>对距离从小到大排序，取出前k个距离最小的事物分类</li>
<li>计算这k个事物中所有便签的出现次数，标签出现次数最多的，为该未知事物的最终分类</li>
</ul>
<a id="more"></a>
<blockquote>
<p>knn算法的python实现</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(input_data, dataSet, lables, k)</span>:</span></span><br><span class="line">  dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">  diffMat = np.tile(input_data, (dataSetSize, <span class="number">1</span>)) - dataSet</span><br><span class="line">  diffMat = diffMat ** <span class="number">2</span></span><br><span class="line">  sqDistance = diffMat.sum(axis = <span class="number">1</span>)</span><br><span class="line">  distance = sqDistance ** <span class="number">0.5</span></span><br><span class="line">  distance = distance.argsort()</span><br><span class="line">  classCount = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    voteLabel = lable[distance[i]]</span><br><span class="line">    classCount[voteLable] = classCount.get(voteLable, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">  classCount = sorted(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">  <span class="keyword">return</span> classCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>其中一些api的解释</p>
</blockquote>
<ul>
<li><p>np.tile(a, b)：a是待处理的对象，b是一个元组；假设有np.tile(1, (3, 2))，表示在行的方向上重复3次，列的方向上重复2次；最后结果如下<br><img src="http://120.24.90.180/blog/image/machine_learning/machine_learning_1.1.png" alt="np.tile()"></p>
</li>
<li><p>argsort()：argsort()函数返回的是数组值从小到大的索引值</p>
</li>
<li><p>sorted(iterable, cmp, key, reverse)：iterable是一个list对象或者是iterator；cmp是带两个参数的比较函数；key是带一个参数的比较函数；reverse是是否逆序；</p>
</li>
<li><p>operator.itemgetter()：是获取对象某个域值的函数，这个不是返回指，而是定义了一个函数</p>
</li>
</ul>
<blockquote>
<p>knn算法的实际演示</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDataSet</span><span class="params">()</span>:</span></span><br><span class="line">  group = np.array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">  lables = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">  <span class="keyword">return</span> group, lables</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">  group, lables = createDataSet()</span><br><span class="line">  input_data = [[<span class="number">1.1</span>, <span class="number">0.9</span>], [<span class="number">0.012</span>, <span class="number">0.01</span>], [<span class="number">0.989</span>, <span class="number">0.996</span>], [<span class="number">0.997</span>, <span class="number">1.003</span>]]</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> input_data:</span><br><span class="line">    <span class="keyword">print</span> classify(i, group, lables, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果</p>
<p><img src="http://120.24.90.180/blog/image/machine_learning/machine_learning_1.2.png" alt="output_data_answer"></p>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="https://www.liaochuntao.cn/2018/01/29/machine-learning-1/" data-id="ckb0yq1e7008k16rlgs6dtpl4" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    
        
  <nav class="article-nav">
    
      <a href="/2018/01/30/machine-learning-2/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            机器学习之决策树
          
        </div>
      </a>
    
    
      <a href="/2018/01/23/leetcode_2/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">leetcode回顾——Two Sum 快速找到两个数字之和等于目标值</div>
      </a>
    
  </nav>


            

                
                    
                        
                            

</article>
</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 春少 Blog</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="春少 Blog"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"left","hOffset":0,"vOffset":-50},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"tagMode":false});</script></body>
</html>