<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  
  
  
    <meta name="description" content="励志成为一位大佬">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    无监督学习算法——KMeans聚类 |
    
    春少 Blog</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>

<body>
<main class="content">
  <section class="outer">
  <article id="post-machine-learning-7" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>

    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="article-title" itemprop="name">
      无监督学习算法——KMeans聚类
    </h1>
  
  




            </header>
            

                
                    <div class="article-meta">
                        <a href="/2018/04/07/machine-learning-7/" class="article-date">
  <time datetime="2018-04-07T14:21:41.000Z" itemprop="datePublished">2018-04-07</time>
</a>
                            
  <div class="article-category">
    <a class="article-category-link" href="/categories/机器学习/">机器学习</a>
  </div>

                    </div>
                    

                        
                            




                                

                                    <div class="article-entry" itemprop="articleBody">
                                        


                                            

                                                
                                                                    <blockquote>
<p>什么是KMeans聚类算法</p>
</blockquote>
<p>K-Means是一种无监督的聚类机器学习算法；之前学习的分类算法，其数据是已经有明确的类别标识了，所以在之前的分类机器学习算法中，算法所要去学习的是如何找到一个或几个特征的组合，能够实现数据的分类操作；但是，在聚类算法中，数据到底可以分为几类是不知道的，只能让算法自行依靠某些规则或约定，对数据进行聚类操作(将可能是同一类别的数据放在一起)。</p>
<p>由于数据的类别我们并不清楚，所以，我们无法监督我们的算法最后的结果是好还是坏，缺乏明确的目标值——这就是无监督机器学习。K-Means算法就是一个典型的无监督机器学习算法。</p>
<p>K-Means算法的原理很像KNN算法，KNN算法是计算未知点到已知点的距离对未知点进行分类处理；K-Means算法则是通过在所有点中找几个中心点，进行计算其他点到各个中心点的距离，距离那个中心点进就归类到那个中心点去，在第一轮归类完后，进行计算每一类的均值，将均值点作为新的中心点，再此重复上述步骤，知道整个归类的结果不再改变时停止上述工作，将这些步骤抽出来简化下就是这样</p>
<p><code>初步选取目前类别个数，选取中心点 ——&gt;&gt; 计算与各个中心点的距离，聚类 &lt;&lt;——{如果聚类结果不再改变，结束}——&gt;&gt; 计算均值，重新确定中心点</code></p>
<a id="more"></a>
<blockquote>
<p>代码实现</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    <span class="string">"""[训练、测试数据文件的加载]</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        fileName &#123;[str]&#125; -- [训练数据集]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [list] -- [训练数据集]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().strip(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = map(float, curLine)</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="string">"""[计算各个点到中心点的距离]</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        vecA &#123;[np.array]&#125; -- [中心点]</span></span><br><span class="line"><span class="string">        vecB &#123;[np.array]&#125; -- [未知点]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [double] -- [距离]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    <span class="string">"""[根据dataSet构建k个随机的中心点]</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        dataSet &#123;[list]&#125; -- [数据集]</span></span><br><span class="line"><span class="string">        k &#123;[int]&#125; -- [聚类目标个数]</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [list] -- [中心点集合]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        minJ = min(dataSet[:, j])</span><br><span class="line">        rangeJ = float(max(dataSet[:, j]) - minJ)</span><br><span class="line">        centroids[:, j] = minJ + rangeJ * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">KMeans</span><span class="params">(dataSet, k, distMeans=distEclud, createCent=randCent)</span>:</span></span><br><span class="line">    <span class="string">"""[K-Means算法主体]</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        dataSet &#123;[list&#125; -- [数据集]</span></span><br><span class="line"><span class="string">        k &#123;[int]&#125; -- [目标聚类个数]</span></span><br><span class="line"><span class="string">    Keyword Arguments:</span></span><br><span class="line"><span class="string">        distMeans &#123;[function]&#125; -- [计算距离的方法] (default: &#123;distEclud&#125;)</span></span><br><span class="line"><span class="string">        createCent &#123;[function]&#125; -- [产生中心点的方法] (default: &#123;randCent&#125;)</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        [tuple] -- [最终每一类的中心点与分配结果]</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    clusterChanged = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            minDist = np.inf; minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                distJI = distMeans(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    minDist = distJI; minIndex = j</span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex:</span><br><span class="line">            <span class="comment"># 聚类结果发生变化</span></span><br><span class="line">                clusterChanged = <span class="keyword">True</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">print</span> centroids</span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 数组元素过滤获取制定簇的数据</span></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 更新中心点的值&#123;均值计算&#125;</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br></pre></td></tr></table></figure>

                                                                        
                                    </div>
                                    <footer class="article-footer">
                                        <a data-url="https://www.liaochuntao.cn/2018/04/07/machine-learning-7/" data-id="ckbaiggxi009216qyoz3s3szi" class="article-share-link">
                                            Share
                                        </a>
                                        
                                    </footer>

    </div>

    
        
  <nav class="article-nav">
    
      <a href="/2018/04/07/deep-learning-4/" class="article-nav-link">
        <strong class="article-nav-caption">Newer</strong>
        <div class="article-nav-title">
          
            keras的回调函数的学习
          
        </div>
      </a>
    
    
      <a href="/2018/04/01/java-web-7/" class="article-nav-link">
        <strong class="article-nav-caption">Older</strong>
        <div class="article-nav-title">数据库链接池原生java-api实现</div>
      </a>
    
  </nav>


            

                
                    
                        
                            

</article>
</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
    <li><i class="fe fe-bookmark"></i> <span id="busuanzi_value_page_pv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 春少 Blog</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>
<aside class="sidebar">
  <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="春少 Blog"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
</aside>
<script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"superSample":2,"width":150,"height":300,"position":"left","hOffset":0,"vOffset":-50},"mobile":{"show":true,"scale":0.5},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false,"tagMode":false});</script></body>
</html>